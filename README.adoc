== How to run

=== Prerequisites

==== Install docker and docker compose

For example, on Mac
[source, bash]
----------
brew install docker-compose
----------

==== Optionally install httpie

For example, on Mac
[source, bash]
----------
brew install httpie
----------

=== To run

[source, bash]
----------
cd ops/
docker-compose up -d
----------

=== To test

Use API documentation (it is generated by tests). 

For gateway: `open gateway/src/main/resources/docs/html/api.html`

For savings service: `open savings-service/src/main/resources/docs/html/api.html`

All examples are for httpie, but you can use curl or any other tool you prefer.

An example of testing timeouts (assuming that docker-compose runs already) and updating the amount:

[source, bash]
----------
http GET 'http://localhost:8080/savings/a/balance'

# you get amount 0 as a response

# now pause the container
docker-compose pause savings-a

# and run the previous command
http GET 'http://localhost:8080/savings/a/balance'

# you'll get 503 error in 5 seconds

# now we can update amount on savings service b
echo '{
 "amount" : 11.05
}' | http POST 'http://localhost:8080/savings/b/balance' \
 'Content-Type:application/json;charset=UTF-8' \
 'Accept:application/json'

# now we stop services
docker-compose down

# and run again
docker-compose up

# and verify that the change is still there
http GET 'http://localhost:8080/savings/b/balance'
----------

== Implementation details

=== Asumptions

1. It's not completely clear what the savings service is. I assume that the idea is to have multiple shards, so Service A manages a shard containing user's A savings, and Service B contains user B savings. So `a` and `b` in `savings/a/balance` is actually a user name (`a` or `b` depending on the path). 
2. It's not defined how the balance should be created. I'd have an API method for that and according to REST conventions it should be `POST`, but `POST` is already reserved for increase/decrease (I'd use `PUT` for that instead). I decided to keep described API (assuming that there could be some scripts on your side that would be broken by API changes). 
3. The initial balance is created by Savings Service itself. It's a bit strange to use a database to keep just one table with one record, but I'm following this requirement. In real life, I'd keep things simple and store this value in a file or some simple distributed storage (S3). 
4. Based on the picture the `amount` in the message bodies is a single field and it looks like a field with a floating-point value. I'd change that as well. Since we obviously pass money in this field, I'd convert the field into an object with at least two fields (one is for currency, another one for amount). Also, I'd pass money in cents (to avoid using floating-point). So, I kept the API but didn't add any validation except for checking for negative numbers. So, for example, "0.9999999" is a valid value currently and I'd avoid such field by changing the API (not by validation). 
5. It's not clear what does "run on port 8081/8082" mean. I just exposed the ports from docker-compose internal network. So each of them can be called directed. In real life, I'd hide the services behind the gateway (because that's the gateway purpose - incapsulate the detials)

=== Testing
The manual test described in <<To test>> is optional. The functionality is covered by unit and integration tests. I also tested the API and generated documentation from these tests. The gateway tests is pretty simple (just because the service is pretty simple). The test is just to check that a request can be proxied and the timeout can be handled. The savings service is a bit more complex, so there are more tests and I used Spock and Testcontainers, since looks like you also use (and hopefully like as much as I like) them. 

== Potential improvements

=== Scaling the API gateway
I don't think that in the current implementation the API gateway is a bottleneck. So, I'd run one more instance just for failover and zero downtime deployment. But usually, a scale intends to improve performance. Since the API gateway is implemented using react streams and an event loop under the hood, I guess it's able to process lots of requests. The bottleneck most probably is savings service. So, as soon as there are performance tests (I was even going to add some simple Gatling tests, but decided to not overcomplicate the setup), I'd start by caching savings service responses on the gateway side and using a cache on the savings service side. And it probably makes more sense to scale savings service (so the cache on its side could be distributive). 
Regarding the failover, zero downtime deployment, and multiple instances, it would require using k8s instead of docker-compose. My initial intent was to use minikube for that project, but it needs more config files and could overcomplicate the setup, so I decided to use docker-compose.

=== Monitor uptime so you can sleep at night
It's not a big deal to add Prometheus and Grafana to the docker-compose file and get monitoring, but it doesn't solve the sleep at night problem. In real life, as soon as we have some usage statistics we can define the rate limits. With the failover (described in the previous section), it should improve SLA and sleep. But to be absolutely safe we need alerting as well (it will not improve our sleep but make customers happier). So, I'd add some alerts on Grafana side and use some services (Statuscake for example) to check availability in different regions (in case we run in different regions). 

=== Secure the gateway
Yes, I can add a couple of dependencies to pom.xml and adjust the application.yaml to issue JWT tokens to force a client to be authenticated to use the API, but that's not enough. To have proper security we need to enable TLS and to do it properly we need some certificates. It involves third parties (letsencrypt for example). So, even if I hardcode the client's name/password (to avoid using a database and skip the registration step) I have to bring more dependencies to the setup. It would also complicate testing (one more step to auth and get token + using the token in auth header in each request). I decided to keep things simple. 

=== Prevent dirty reads and writes

Since all requests go through the API getaway we can leverage it to prevent dirty reads and writes. Imagine that there are two users U1 and U2. U1 is transferring money from A to B. We have no transactions, so user U2 can run `/savings/a/balance
` and `/savings/b/balance
` after U1 reduced amount on A but before U1 increased amount on B. So U2 sees the system in an inconsistent state (there is less money in the system). Fixing that problem requires changing the API (to introduce transactions) and brings some challenges. We need to keep an additional state on the gateway size, so it's not stateless anymore which complicates its scalability. But it would improve user experience significantly. 
